# One-way independent ANOVA {.section}

Compare 2 or more independent groups.

## Assumptions

Assuming th $H_0$ hypothesis to be true, the following should hold:

* Continuous variable
* Random sample
* Normaly distributed
    * Shapiro-Wilk test
* Equal variance within groups
    * Levene's test

## Jet lag

Wright and Czeisler (2002) performed an experiment where they measured the circadian rhythm by the daily cycle of melatonin production in 22 subjects randomly assigned to one of three light treatments.

* Control condition (no light)
* Knees (3 hour light to back of knees)
* Eyes (3 hour light in eyes)

```{r}
rm(list=ls())
x.c = c( .53, .36,  .2,  -.37, -.6,  -.64, -.68,-1.27) # Control 
x.k = c( .73, .31,  .03, -.29, -.56, -.96,-1.61      ) # Knees
x.e = c(-.78,-.86,-1.35,-1.48,-1.52,-2.04,-2.83      ) # Eyes
x   = c( x.c, x.k, x.e )                               # Conditions combined
```

```{r, echo=FALSE}
lab = c("Control", "Knee", "Eyes") 

k_v  = c(rep(1,length(x.c)), 
         rep(2,length(x.k)), 
         rep(3,length(x.e)))       # vector met 1, 2 en 3 corresponderend met de scores.

plot(k_v,x, 
     col="red",
     main='Response to light treatment',
     ylab="Shift in circadian rhythm (h)",
     xlab="Light treatment",
     xlim=c(.5,3.5),
     xaxt="n")
axis(1,at=1:3,labels=lab)

lines(c(1,1.2,1.1,1.1,1,1.2),
      c(rep((mean(x.c)-((sd(x.c)/sqrt(length(x.c))))),3),
        rep((mean(x.c)+((sd(x.c)/sqrt(length(x.c))))),3))
     )
lines(c(2,2.2,2.1,2.1,2,2.2),
      c(rep((mean(x.k)-((sd(x.k)/sqrt(length(x.k))))),3),
        rep((mean(x.k)+((sd(x.k)/sqrt(length(x.k))))),3))
     )
lines(c(3,3.2,3.1,3.1,3,3.2),
      c(rep((mean(x.e)-((sd(x.e)/sqrt(length(x.e))))),3),
        rep((mean(x.e)+((sd(x.e)/sqrt(length(x.e))))),3))
     )
points(c(1,2,3)+.1,c(mean(x.c),mean(x.k),mean(x.e)),bg="red",pch=21)
```

## Variance components

Variance | Sum of Squares | DF | Mean Squares | F-ratio
---------|----------------|----|--------------|---------
Model    | ${SS}_{model} = \sum n_k(\bar{X}_k - \bar{X})^2$ | $k-1$ | $\frac{{SS}_{model}}{{df}_{model}}$ | $\frac{{MS}_{model}}{{MS}_{error}}$
Error    | ${SS}_{error} = \sum s_k^2 (n_k - 1)$            | $N-k$ | $\frac{{SS}_{error}}{{df}_{error}}$ | 
Total    | ${SS}_{total} = {SS}_{model} + {SS}_{error}$     | $N-1$ | $\frac{{SS}_{total}}{{df}_{total}}$ | 

Where $N$ is the total sample size, $n_k$ is the sample size per category and $k$ is the number of categories. Finally $s_k^2$ is the variance per category.

## Total variance {.subsection}

$${MS}_{total} = s_x^2$$

```{r}
ms.t = var(x); ms.t

sum( (x - mean(x))^2 ) / (length(x) - 1)
```

--------

$${SS}_{total} = s_x^2 (N-1)$$

```{r}
N = length(x)

ss.t = var(x) * (N-1); ss.t

sum( (x - mean(x))^2 )
```

## Visual ${SS}_{total}$ {.smaller}

```{r}
# Assign labels
lab = c("Control", "Knee", "Eyes") 

# Plot all data points
plot(1:N,x, 
     ylab="Shift in circadian rhythm (h)",
     xlab="Light treatment",
     main="Total variance")

# Add mean line
lines(c(1,22),rep(mean(x),2),lwd=3)

# Add delta lines / variance components
segments(1:N, mean(x), 1:N, x)

# Add labels
text(c(4,11.5,18.5),rep(.6,3),labels=lab)
```

## Model variance {.smaller .subsection}

$${MS}_{model} = \frac{{SS}_{model}}{{df}_{model}} \\ {df}_{model} = k - 1$$

Where $k$ is the number of independent groups and

$${SS}_{model} = \sum_{k} n_k (\bar{X}_k - \bar{X})^2$$

```{r}
k      = 3
n.c = length(x.c)
n.k = length(x.k)
n.e = length(x.e)
```

--------

```{r}
ss.m.c = n.c * (mean(x.c) - mean(x))^2
ss.m.k = n.k * (mean(x.k) - mean(x))^2
ss.m.e = n.e * (mean(x.e) - mean(x))^2

ss.m = sum(ss.m.c, ss.m.k, ss.m.e); ss.m
df.m = (k - 1)
ms.m = ss.m / df.m; ms.m
```

## Visual ${SS}_{model}$

```{r, echo=FALSE}
# Assign labels
lab = c("Control", "Knee", "Eyes") 

# Plot all data points
plot(1:N,x, 
     ylab="Shift in circadian rhythm (h)",
     xlab="Light treatment",
     main="Total variance")

# Add mean line
lines(c(1,22),rep(mean(x),2),lwd=3)

# Add delta lines / variance components
segments(1:N, mean(x), 1:N, x)

# Add labels
text(c(4,11.5,18.5),rep(.6,3),labels=lab)

# Add model means lines
lines(c( 1,8 ),rep(mean(x.c),2),col="red",  lwd=3)
lines(c( 9,15),rep(mean(x.k),2),col="blue", lwd=3)
lines(c(16,22),rep(mean(x.e),2),col="green",lwd=3)

# Add model delta lines
segments(1:8,   mean(x.c), 1:8,   mean(x), col="red",  lwd=3)
segments(9:15,  mean(x.k), 9:15,  mean(x), col="blue", lwd=3)
segments(16:22, mean(x.e), 16:22, mean(x), col="green",lwd=3)
```

## Error variance {.subsection}

$${MS}_{error} = \frac{{SS}_{error}}{{df}_{error}} \\ {df}_{error} = N - k$$

where

$${SS}_{error} = \sum_{k} s_k^2 (n_k - 1) = \sum_{k} \frac{\sum (x_{ik} - \bar{x}_k)^2}{(n_k - 1)} (n_k - 1)$$

```{r}
ss.e.c = var(x.c) * (n.c - 1)
ss.e.k = var(x.k) * (n.k - 1)
ss.e.e = var(x.e) * (n.e - 1)
ss.e   = sum(ss.e.c, ss.e.k, ss.e.e); ss.e
```

-----

$${MS}_{error} = \frac{{SS}_{error}}{{df}_{error}} \\ {df}_{error} = N - k$$

```{r}
df.e = (N - k)
ms.e = ss.e / df.e; ms.e
```

## Visual ${SS}_{error}$

```{r, echo=FALSE}
# Assign labels
lab = c("Control", "Knee", "Eyes") 

# Plot all data points
plot(1:N,x, 
     ylab="Shift in circadian rhythm (h)",
     xlab="Light treatment",
     main="Total variance")

# Add mean line
lines(c(1,22),rep(mean(x),2),lwd=3)

# Add delta lines / variance components
segments(1:N, mean(x), 1:N, x)

# Add labels
text(c(4,11.5,18.5),rep(.6,3),labels=lab)

# Add model means lines
lines(c( 1,8 ),rep(mean(x.c),2),col="red",  lwd=3)
lines(c( 9,15),rep(mean(x.k),2),col="blue", lwd=3)
lines(c(16,22),rep(mean(x.e),2),col="green",lwd=3)

# Add model delta lines
segments(1:8,   mean(x.c), 1:8,   mean(x), col="red",  lwd=3)
segments(9:15,  mean(x.k), 9:15,  mean(x), col="blue", lwd=3)
segments(16:22, mean(x.e), 16:22, mean(x), col="green",lwd=3)

# Add error lines
segments(1:8,   mean(x.c), 1:8,   x.c, col="purple", lwd=3)
segments(9:15,  mean(x.k), 9:15,  x.k, col="purple", lwd=3)
segments(16:22, mean(x.e), 16:22, x.e, col="purple", lwd=3)
```

## Variance components {.subsection}

$${SS}_{total} = {SS}_{model} + {SS}_{error}$$
$$`r ss.t` = `r ss.m` + `r ss.e`$$

$${MS}_{total} = \frac{{SS}_{total}}{{df}_{total}}= `r ms.t`$$
$${MS}_{model} = \frac{{SS}_{model}}{{df}_{model}}= `r ms.m`$$
$${MS}_{error} = \frac{{SS}_{error}}{{df}_{error}} = `r ms.e`$$

## F-ratio {.subsection}

$$F = \frac{{MS}_{model}}{{MS}_{error}} = \frac{{SIGNAL}}{{NOISE}}$$

```{r}
F = ms.m / ms.e; F
```

## Reject $H_0$?

```{r}
if(!"visualize" %in% installed.packages()) { install.packages("visualize") }
library("visualize")

visualize.f(F, df.m,df.e,section="upper")
```

## Contrasts

Planned comparisons

* Exploring differences of theoretical interest
* Higher precision
* Higher power

## Contrasts

* Only use chunks once
* Values add up to 0

<img src="../../../topics/ANOVA_one_way_independent/pie2.png" style="height:200px;" >
<img src="../../../topics/ANOVA_one_way_independent/pie1.png" style="height:200px;" >

------

<img src="../../../topics/ANOVA_one_way_independent/pie3.png" style="height:200px;" >

* AB-CDEF &rarr; A-B &rarr; CD-EF &rarr; C-D &rarr; E-F
* A-BCDEF &rarr; A-B &rarr; A-C
* A-BCDEG &rarr; BC-DEF &rarr; B-C &rarr; B-DEF
* ABC-DEF &rarr; BC-DEF &rarr; B-C

-------

Assign values that combine to one. Same values define chunk.

* AB-CDEF &rarr; A-B &rarr; CD-EF &rarr; C-D &rarr; E-F

|            |A|B|C|D|E|F
|------------|-|-|-|-|-|-
| Contrast 1 | | | | | |
| Contrast 2 | | | | | |
| Contrast 3 | | | | | |
| Contrast 4 | | | | | |


```{r, echo=FALSE, fig.height=6}
# ANOVA 
# Concept van verklaarde variantie

layout(matrix(1:3,3,1))

# Laten we eerst wat data genereren

set.seed(1)           # om ervoor te zorgen dat we elke keer dezelfde getallen krijgen
n = 1:9               # aantal proefpersonen
f = rep(1:3,each = 3) # aantal categorien
x = rnorm(n,5,1)      # behaalde scores

# Losse variabelen in een data frame stoppen
data = data.frame(n,f,x)

# Data even bekijken
# data

# en ook in een plot
plot(data[,c('n','x')],main='variance explained')

# Om te weten hoeveel variantie er in totaal is hebben we het gemiddelde nodig

data$meanx <- mean(x)

# Laten we ook het gemiddelde van x plotten
lines(data$n,data$meanx,col='grey',lty=2)

# De hoeveelheid variatie van alle datapunten x ten opzichte van het gemiddelde van x kan worden aangegeven met de afstand tussen de datapunten en het gemiddelde

for(r in 1:9) {
row = data[r,]
lines(rep(row$n,2),c(row$x,row$meanx), col='blue')
}

# De blauwe lijnen

# We kunnen deze variantie proberen te verklaren met het groepslidmaatschap. Met andere woorden de categorien / factoren.

# Hiervoor hebben we de gemiddelden in de drie groepen nodig.

mean_f1 = colMeans(subset(data, f == 1, select = 'x')); 
mean_f2 = colMeans(subset(data, f == 2, select = 'x')); 
mean_f3 = colMeans(subset(data, f == 3, select = 'x')); 

# Laten we deze groepsgemiddelden toevoegen aan de dataset
data$groupmean <- c(rep(mean_f1,3),rep(mean_f2,3),rep(mean_f3,3))

# en vervolgens toevoegen aan de plot

lines(1:3, rep(mean_f1,3), col='grey', lwd=2)
lines(4:6, rep(mean_f2,3), col='grey', lwd=2)
lines(7:9, rep(mean_f3,3), col='grey', lwd=2)

# De totale variantie wordt dus voor een deel door het groepslidmaatschap (de groene lijn) veklaard. Het overige onverklaarde deel zijn de afstanden van x tot de groepsgemiddelden.

for(r in 1:9) {
row = data[r,]
lines(rep(row$n,2)+.05,c(row$groupmean,row$x),     col='red' )
lines(rep(row$n,2)-.05,c(row$groupmean,row$meanx), col='green')
}

# De totale variantie van de blauwe lijnen bestaat dus uit de afstand van het totale gemiddelde tot de groepsgemiddelden plus de afstand van de groepsgemiddelden tot de afzonderlijke x-en.

# blauw = groen + rood
# SS_T  = SS_M  + SS_E
# MS_T  = MS_M  + MS_E

# De F waarde die we toetsen bestaat uit de verhouding verklaarde variantie door het model en de onverklaarde variantie van de error.

# F = MS_M / MS_E

##############
# Contrasten #
##############

# Een goed contrast overschreidt nooit de hoeveelheid totale variantie.

# Stel dat we de eerste twee factoren willen contrasteren met de derde en daarna de eerste twee met elkaar. 

# We kunnen dan: MS_T = MS_M + MS_E ook schrijven als:

# MS_T = MS_mg1  + MS_eg1 +
#        MS_mg23 + MS_mg2 + MS_eg2 +
#                  MS_mg3 + MS_eg3

# In grafiek:

## Contrast 1

# datapunten
plot(data[,c('n','x')],main='Contranst 1+2 with 3')
# totaal gemiddelde van x
lines(data$n,data$meanx,col='grey',lty=2)
# totale variantie
for(r in 1:9) {
row = data[r,]
lines(rep(row$n,2),c(row$x,row$meanx), col='blue')
}
# groep gemiddelden
lines(7:9, rep(mean_f3,3), col='grey', lwd=2)

# gemiddelde van contrast vergelijking factor 1 en 2
mean_f12 = colMeans(subset(data, f <= 2 , select = 'x')); 

# toevoegen aan grafiek
lines(1:6, rep(mean_f12,6), col='grey', lwd=2)

# variantie componenten
for(r in 1:6) {
row = data[r,]
# lines(rep(row$n,2)+.05,c(row$groupmean,row$x),    col='red'  )
lines(rep(row$n,2)+.05,c(row$x,    mean_f12), col='red')
lines(rep(row$n,2)-.05,c(row$meanx,mean_f12), col='green')
}
# variantie componenten
for(r in 7:9) {
row = data[r,]
lines(rep(row$n,2)+.05,c(row$groupmean,row$x),     col='red' )
lines(rep(row$n,2)-.05,c(row$groupmean,row$meanx), col='green')
}

## Contrast 2

# datapunten
plot(data[,c('n','x')],main='Contranst 1 with 2')

lines(data$n,data$meanx,col='grey',lty=2)

# groep gemiddelden
lines(1:3, rep(mean_f1,3), col='grey', lwd=2)
lines(4:6, rep(mean_f2,3), col='grey', lwd=2)


# gemiddelde van contrast vergelijking factor 1 en 2
mean_f12 = colMeans(subset(data, f <= 2 , select = 'x')); 

# totale variantie
for(r in 1:6) {
row = data[r,]
lines(rep(row$n,2),c(row$x,row$meanx), col='blue')
}

# toevoegen aan grafiek
lines(1:6, rep(mean_f12,6), col='grey', lwd=2)

# variantie componenten
for(r in 1:6) {
row = data[r,]
lines(rep(row$n,2)+.05,c(row$groupmean,row$x),    col='red'  )
lines(rep(row$n,2)-.05,c(row$groupmean,mean_f12), col='green')
}
```

## Post-hoc

Unplanned comparisons

* Exploring all possible differences
* Adjust T value for inflated type 1 error

| |C|K|E
|-|-|-|-
|C| |2|3 
|K|4| |6 
|E|7|8| 

## Effect size $\eta^2$

The amount of explained variance $R^2$ as a general effect size measure.

$$R^2 = \frac{{SS}_{model}}{{SS}_{total}} = \eta^2$$
Taking the square root gives us Cohen's $r$.

## Effect size $\omega^2$

Less biased towards just the sample is omega squared $\omega^2$.

$$\omega^2 = \frac{{SS}_{model} - ({df}_{model}){MS}_{error}}{{SS}_{total}+{MS}_{error}}$$
But what does it say?

## Effect size $r$

A more interpretable effect size measure is $r_{Contrast}$. Which gives the effect size for a specific contrast.

$$r_{Contrast} = \sqrt{\frac{t^2}{t^2+{df}}}$$