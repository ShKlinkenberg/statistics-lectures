# Null Hypothesis<br>Significance Testing {.section}

## Neyman-Pearson Paradigm

![](https://upload.wikimedia.org/wikipedia/commons/8/8e/Jerzy_Neyman2.jpg){.absolute top=150 left=0 height="300"}

![](https://upload.wikimedia.org/wikipedia/en/a/a2/Egon_Pearson.jpg){.absolute top=150 left=200 height="300"}

[Neyman](https://en.wikipedia.org/wiki/Jerzy_Neyman) - [Pearson](https://en.wikipedia.org/wiki/Egon_Pearson)

## Two hypothesis

<table style="width:100%; border: none;">
  
<tr><td>

$H_0$

* Skeptical point of view
* No effect
* No preference
* No Correlation
* No difference

</td><td>

$H_A$

* Refute Skepticism
* Effect
* Preference
* Correlation
* Difference

</td></tr></table>

## Frequentist probability

* Objective Probability
* Relative frequency in the long run

## Standard Error

> 95% confidence interval 


$$SE = \frac{\text{Standard deviation}}{\text{Square root of sample size}} = \frac{s}{\sqrt{n}}$$


* Lowerbound = $\bar{x} - 1.96 \times SE$
* Upperbound = $\bar{x} + 1.96 \times SE$

## Standard Error {.flexbox .vcenter}


```{r, child="ci.html"}
```


##


```{r, echo=FALSE, out.height=600}
set.seed(1548)

x  = seq(-4,4,.05) # sequence x values for normal distribution
hx = dnorm(x)      # calculate y values

title = expression(atop("SAMPLES FROM NORMAL DISTRIBUTION",paste(mu," falls within the CI in ~95% of the samples")))

plot(x,hx+1,type="l",ylim=c(0,1.45),xlim=c(-4,9), yaxt="n", xaxt="n",ylab="",xlab="",main=title, mai=c(3,1,2,1),mar=c(3,1,2,1))

# Add red area
polygon(c(x,rev(x)),c(rep(1,length(x)),hx+1),col="red",lty=1)

# Add mu line
lines(c(0,0),c(0,max(hx)+1))

# Add mu symbol to x axis
axis( 1,at=0,labels=expression(mu), cex=2 )

# Create curly braces for normal distribution 
ybracket = seq(1,max(hx)+1,length=39)
xbracket = rep(4.1,39)*c(c(1,1.02),rep(1.03,16),c(1.04,1.05,1.04),rep(1.03,16),c(1.02,1))

lines(xbracket,ybracket,col="black")

# Create curly braces for samples
ybracket = seq(0,1,length=39)
xbracket = rep(4.1,39)*c(c(1,1.02),rep(1.03,16),c(1.04,1.05,1.04),rep(1.03,16),c(1.02,1))

lines(xbracket,ybracket,col="black")

text = expression(atop("Normally distributed","population"))

text(4.1*1.06,1+(max(hx)/2), text,pos=4)

text = expression(atop("95% Confidence interval","in 100 samples","drawn from the","normal distribution"))

text(4.1*1.06,.5, text,pos=4)

# Add confidence intervals

mu  = 0
sig = 1

mu_in_ci = array() # create empty array

iterations = 100

for(i in 1:iterations) {
	
	n      = round(runif(1,10,60)) # use variable sample sizes between 10 and 60
	sample = rnorm(n,mu,sig)       # sample from normal distribution
	
	sample_mean = mean(sample)
	sample_sd   = sd(sample)
	sample_ci   = sample_sd/sqrt(n)

	sample_ci_upperbound = sample_mean + sample_ci * 1.96
	sample_ci_lowerbound = sample_mean - sample_ci * 1.96
	
	if(sample_ci_lowerbound < mu & sample_ci_upperbound > mu) {
		
		mu_in_ci[i] = 1	
		col = "darkgrey"	
		}
	else {
		mu_in_ci[i] = 0
		col = "red"
		}
    
    # plot CI lines
    lines(c(sample_ci_lowerbound,sample_ci_upperbound),rep((.98/iterations)*i,2),col=col)

	}
	
percentage = (1/iterations)*sum(mu_in_ci)
```




## Binomial $H_0$ distribution


```{r, echo=TRUE}
#| output-location: slide

n = 10   # Sample size
k = 0:n  # Discrete probability space
p = .5   # Probability of head

munt = 0:1

permutations = factorial(n) / ( factorial(k) * factorial(n-k) )
# permutations

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event

title = "Binomial Null distribution"

# col=c(rep("red",2),rep("beige",7),rep("red",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:n, 
         xlab="number of head", 
         ylab="P(%)", 
         col='beige',
         ylim=c(0,.3) )

# abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## Binomial $H_A$ distributions


```{r, echo=FALSE}

# n = 10   # Sample size
# k = 0:10 # Discrete probability space
prob = c(.2, .4, .6, .8)  # Probability of head

layout(matrix(1:4, 2,2)) 

for(p in prob) {
permutations = factorial(n) / ( factorial(k) * factorial(n-k) )

p_k2  = p^k  * (1-p)^(n-k)  # Probability of single event
p_kp2 = p_k2 * permutations # Probability of event times 
                            # the occurrence of that event

title = "Binomial alternative distribution"

col=c(rep("red",2),rep("beige",7),rep("red",2))

barplot( p_kp2, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         beside=TRUE,
         col="beige",
         ylim=c(0,.3) 
         )

# abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp2,round(p_kp2,3),pos=3,cex=.5)
}
```


## Decision table

::: {.content-visible when-format="revealjs"}

<style>
#dectable > svg { transform: scale(1.4);}
</style>

:::



::: {.r-stack #dectable .r-stretch}

```{r child="decision_table.svg"}
```

:::

## Alpha $\alpha$

:::: {.columns}

::: {.column width="40%"}

* Incorrectly reject $H_0$
* Type I error
* False Positive
* Criteria often 5%
* Distribution depends on sample size

:::

::: {#alpha .column width="60%"}

<style>
#alpha .alpha { stroke: black;}
#alpha > svg { transform: scale(.8);}
</style>


```{r child="decision_table.svg"}
```


:::

::::

##


```{r, echo=FALSE}

n = 10   # Sample size
k = 0:10 # Discrete probability space
p = .5   # Probability of head

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event
# sample = 90
# freq_munt = round(p_kp*sample)
# cbind(k,permutations,p_k,p_kp,freq_munt)

title = "Binomial Null distribution"

col=c(rep("red",2),rep("beige",7),rep("red",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col=col,
         ylim=c(0,.3) )

abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## Power

:::: {.columns}

::: {.column width="40%"}

* Correctly reject $H_0$
* True positive
* Power equal to: 1 - Beta
    * Beta is Type II error
* Criteria often 80%
* Depends on sample size

:::

::: {#power .column width="60%"}

<style>
#power .power { stroke: black; }
#power > svg { transform: scale(.8);}
</style>


```{r child="decision_table.svg"}
```


:::

::::

##


```{r, echo=FALSE}

n = 10   # Sample size
k = 0:10 # Discrete probability space
p = .25   # Probability of head

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event
# sample = 90
# freq_munt = round(p_kp*sample)
# cbind(k,permutations,p_k,p_kp,freq_munt)

title = "Binomial alternative distribution"

col=c(rep("red",2),rep("beige",7),rep("red",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col=col,
         ylim=c(0,.3) )

abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## Post-Hoc Power

* Also known as: observed, retrospective, achieved, prospective and a priori power
* Specificly meaning:

> The power of a test assuming a population effect size equal to the observed effect size in the current sample.

Source: [O'Keefe (2007)](http://www.dokeefe.net/pub/okeefe07cmm-posthoc.pdf)

## Effect size

In statistics, an effect size is a quantitative measure of the strength of a phenomenon.  Examples of effect sizes are the correlation between two variables, the regression coefficient in a regression, the mean difference and standardised differences.

For each type of effect size, a larger absolute value always indicates a stronger effect. Effect sizes complement statistical hypothesis testing, and play an important role in power analyses, sample size planning, and in meta-analyses.

Source: [WIKIPEDIA](https://en.wikipedia.org/wiki/Effect_size)

## Effect size {.flexbox .vcenter}

![](../../../../topics/NHST/effec_size.png)

## One minus alpha

:::: {.columns}

::: {.column width="40%"}

* Correctly accept $H_0$
* True negative

:::

::: {#oneminalpha .column width="60%"}

<style>
#oneminalpha .oneminalpha { stroke: black; }
#oneminalpha > svg { transform: scale(.8);}
</style>


```{r child="decision_table.svg"}
```


:::

::::

##


```{r, echo=FALSE}

n = 10   # Sample size
k = 0:10 # Discrete probability space
p = .5   # Probability of head

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event
# sample = 90
# freq_munt = round(p_kp*sample)
# cbind(k,permutations,p_k,p_kp,freq_munt)

title = "Binomial Null distribution"

col=c(rep("beige",2),rep("red",7),rep("beige",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col=col,
         ylim=c(0,.3) )

abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## Beta

:::: {.columns}

::: {.column width="40%"}

* Incorrectly accept $H_0$
* Type II error
* False Negative
* Criteria often 20%
* Distribution depends on sample size

:::

::: {#beta .column width="60%"}

<style>
#beta .beta { stroke: black; }
#beta > svg { transform: scale(.8);}
</style>


```{r child="decision_table.svg"}
```


:::

::::


##


```{r, echo=FALSE}

n = 10   # Sample size
k = 0:10 # Discrete probability space
p = .25   # Probability of head

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event
# sample = 90
# freq_munt = round(p_kp*sample)
# cbind(k,permutations,p_k,p_kp,freq_munt)

title = "Binomial alternative distribution"

col=c(rep("beige",2),rep("red",7),rep("beige",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col=col,
         ylim=c(0,.3) )

abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## 


```{r, echo=FALSE}

title = "Both distributions"

colh0 = 'darkgreen'
colha = 'darkorange'

barplot( rbind(dbinom(0:10, 10, .5),
               dbinom(0:10, 10, .2)), 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col = rbind(colh0,colha),
         beside=TRUE
         #legend.text = c("H0", "HA")
         )

abline(v = c(6.5,27.5), lty=2, col='red')

legend("topright", legend=c("H0","HA"), fill=c(colh0, colha))

```


## P-value

> Conditional probability of the found test statistic or more extreme assuming the null hypothesis is true.

Reject $H_0$ when:

* $p$-value $\leq$ $alpha$

## P-value in $H_{0}$ distribution


```{r, echo=FALSE}

n = 10   # Sample size
k = 0:10 # Discrete probability space
p = .5   # Probability of head

p_k  = p^k * (1-p)^(n-k)  # Probability of single event
p_kp = p_k * permutations # Probability of event times 
                          # the occurrence of that event
# sample = 90
# freq_munt = round(p_kp*sample)
# cbind(k,permutations,p_k,p_kp,freq_munt)

title = "Binomial Null distribution"

col=c(rep("blue",3),rep("beige",5),rep("blue",2))

barplot( p_kp, 
         main=title, 
         names.arg=0:10, 
         xlab="number of head", 
         ylab="P(%)", 
         col=col,
         ylim=c(0,.3) )

abline(v = c(2.5,10.9), lty=2, col='red')

text(.6:10.6*1.2,p_kp,round(p_kp,3),pos=3,cex=.5)
```


## Test statistics

Some common test statistics

* Number of heads
* Sum of dice
* Difference
* $t$-statistic
* $F$-statistic
* $\chi^2$-statistic
* etc...

## Decision Table {.flexbox .vcenter .smaller}


```{r, echo=TRUE}
#| output-location: slide

N     = 10  # Sample size
H0    = .5  # Probability of head under H0 50/50
HA    = .2  # Aternative expected value
alpha = .05 # Selected type I error

# Color areas red for selected alpha
area <- dbinom(0:N, N, H0) < alpha/2

# barplot(dbinom(0:N,N, HA)) -> x.values

# x.values
# lb <- x.values[c(qbinom(alpha/2, N+1, H0), qbinom(alpha/2, N+1, H0)+1 )]
# ub <- x.values[c(qbinom(1-(alpha/2), N+1, H0), qbinom(1-(alpha/2), N+1, H0)+1 )]
# 
# mlb <- mean(lb)
# mub <- mean(ub)

col = rep("beige", N+1)
col[area] = "red"

col2 = rep("red", N+1)
col2[area] = "beige"

# Delete # to not color the plots
# col = col2  = "beige"

layout(matrix(1:9,3,3, byrow=T))

plot.new()
text(0.5,0.5,"Binomial Distribution",cex=1.5)
# text(0.5,0.1,paste("N:",N),cex=1.5)

plot.new()
text(0.5,0.5,"H0 True",cex=2)

plot.new()
text(0.5,0.5,"H0 False",cex=2)

plot.new()
text(0.5,0.5,"Reject H0",cex=2)

barplot(dbinom(0:N,N, H0), 
        col  = col, 
        # yaxt = 'n', 
        main = 'Alpha / Type I error', 
        names.arg = 0:N, 
        cex.names = 0.7)


# abline(v = mlb, col="red", lwd=3, lty=2)
# abline(v = mub, col="red", lwd=3, lty=2)

barplot(dbinom(0:N,N, HA), 
        col  = col, 
        yaxt = 'n', 
        main = 'Power', 
        names.arg = 0:N, 
        cex.names = 0.7)

plot.new()
text(0.5,0.5,"Accept H0",cex=2)

barplot(dbinom(0:N,N, H0), 
        col  = col2, 
        # yaxt = 'n', 
        main = '1 - alpha', 
        names.arg = 0:N, 
        cex.names = 0.7)

barplot(dbinom(0:N,N, HA), 
        col  = col2, 
        yaxt = 'n', 
        main = 'Beta / Type II error', 
        names.arg = 0:N, 
        cex.names = 0.7)
```


## Reasoning Scheme {.subsection .flexbox .vcenter}

![](../../../../topics/NHST/NHST_descision_scheme.png)

## R<-PSYCHOLOGIST {background-iframe="http://rpsychologist.com/d3/NHST/"}





